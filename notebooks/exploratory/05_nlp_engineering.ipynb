{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe9ec0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Baixar recursos do nltk (somente na primeira vez)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vbitu\\anaconda3\\envs\\fake-news-etl-v2\\Lib\\site-packages\\nltk\\__init__.py:180\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download, download_shell\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtkinter\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vbitu\\anaconda3\\envs\\fake-news-etl-v2\\Lib\\site-packages\\nltk\\downloader.py:2475\u001b[39m\n\u001b[32m   2465\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   2468\u001b[39m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# Main:\u001b[39;00m\n\u001b[32m   2470\u001b[39m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2473\u001b[39m \n\u001b[32m   2474\u001b[39m \u001b[38;5;66;03m# Aliases\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2475\u001b[39m _downloader = \u001b[43mDownloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2476\u001b[39m download = _downloader.download\n\u001b[32m   2479\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_shell\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vbitu\\anaconda3\\envs\\fake-news-etl-v2\\Lib\\site-packages\\nltk\\downloader.py:515\u001b[39m, in \u001b[36mDownloader.__init__\u001b[39m\u001b[34m(self, server_index_url, download_dir)\u001b[39m\n\u001b[32m    513\u001b[39m \u001b[38;5;66;03m# decide where we're going to save things to.\u001b[39;00m\n\u001b[32m    514\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._download_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     \u001b[38;5;28mself\u001b[39m._download_dir = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_download_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vbitu\\anaconda3\\envs\\fake-news-etl-v2\\Lib\\site-packages\\nltk\\downloader.py:1068\u001b[39m, in \u001b[36mDownloader.default_download_dir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1066\u001b[39m \u001b[38;5;66;03m# Check if we have sufficient permissions to install in a\u001b[39;00m\n\u001b[32m   1067\u001b[39m \u001b[38;5;66;03m# variety of system-wide locations.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nltkdir \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m.path:\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(nltkdir) \u001b[38;5;129;01mand\u001b[39;00m nltk.internals.is_writable(nltkdir):\n\u001b[32m   1070\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m nltkdir\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# NLP - Engenharia de Features - Etapa 1\n",
    "# Pré-processamento de Texto\n",
    "# =========================\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "# Baixar recursos do nltk (somente na primeira vez)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Carregando o modelo do spaCy para português\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "# Carregando o dataset unificado (ajustar o path se necessário)\n",
    "df_unificado = pd.read_csv(r'C:\\Users\\vbitu\\projects\\fake-news-etl-project\\data\\processed\\dados_unificado.csv')\n",
    "\n",
    "# Função de limpeza de texto\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()  # minúsculas\n",
    "    text = re.sub(r'http\\S+', '', text)  # remover links\n",
    "    text = re.sub(r'\\d+', '', text)  # remover números\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remover pontuação\n",
    "    \n",
    "    words = word_tokenize(text, language='portuguese')\n",
    "    words = [word for word in words if word not in stopwords.words('portuguese')]\n",
    "    \n",
    "    doc = nlp(\" \".join(words))\n",
    "    lemmatized = [token.lemma_ for token in doc]\n",
    "    \n",
    "    return \" \".join(lemmatized)\n",
    "\n",
    "# Aplicando na coluna de texto (nome da coluna é conteudo_completo))\n",
    "df_unificado['texto_limpo'] = df_unificado['conteudo_completo'].apply(clean_text)\n",
    "\n",
    "# Visualizando resultado inicial\n",
    "df_unificado[['conteudo_completo', 'texto_limpo']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c786be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\vbitu\\\\projects\\\\fake-news-etl-project\\\\notebooks\\\\exploratory'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85609a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_scraping_exploratorio.ipynb',\n",
       " '02_scraping_detalhes.ipynb',\n",
       " '02_scraping_detalhes.py',\n",
       " '03_preprocessing_merge.ipynb',\n",
       " '03_scrapping_api.py',\n",
       " '04_eda_inicial.ipynb',\n",
       " '04_scraping_detalhes_playwright.py',\n",
       " '05_nlp_engineering.ipynb']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news-etl-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
